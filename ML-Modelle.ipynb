{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einleitung: Klassifikation von Fonds in Peergroups mit ML\n",
    "\n",
    "### Problemstellung\n",
    "\n",
    "Die Einordnung neuer Fonds in Peergroups erfolgt aktuell manuell durch Mitarbeiter. Dafür müssen Informationen aus dem Internet recherchiert und die Fonds individuell analysiert werden. Des Weiteren muss regelmäßig durch aufwendige Analysen geprüft werden, ob Fonds neu klassifiziert werden müssen. Mit steigender Zahl an Fonds und Peergroups wird dieser Prozess zunehmend aufwendig und fehleranfällig. Zusätzlich wird es bei zunehmender Anzahl an Peergroups schwierig zu erkennen, ob diese die Fonds noch klar genug trennen können.\n",
    "\n",
    "### Ziel\n",
    "\n",
    "Zielsetzung dieses Projektteils ist es, mithilfe von Machine-Learning-Modellen automatisch Vorschläge für die Zuordnung eines Fonds zu einer oder mehreren Peergroups zu erzeugen. Damit soll entweder der manuelle Aufwand entfallen oder der Mitarbeiter bei der Einordnung unterstützt werden.\n",
    "\n",
    "Des Weiteren soll ein Clustering helfen zu prüfen, welche Fonds ein ähnliches Rendite-Risiko-Profil aufweisen. Dadurch kann erkannt werden, wie stark sich Fonds unterschiedlicher Peergroups in diesem Aspekt unterscheiden, und es können Rückschlüsse auf die Peergroup-Zusammensetzung gezogen werden.\n",
    "\n",
    "### Feature-Auswahl\n",
    "\n",
    "Für die Klassifikation wurden nur Daten genutzt, die für alle Fonds in der Breite verfügbar sind:\n",
    "- rollierende Basis-Kennzahlen, die aus den Renditezeitreihen berechnet werden,\n",
    "- Korrelationen zu unterschiedlichen Anlageklassen,\n",
    "- sowie der Fondsname.\n",
    "\n",
    "Detailliertere Informationen wie Strategietexte, Ratings und weitere Stammdaten wurden bewusst nicht genutzt, da diese nicht für alle Fonds verfügbar sind. Die Klassifizierung ist zudem vor allem bei internen Analysen über Produkte interessant, die nicht frei gehandelt werden und bei denen oft nur eine Rendite-Zeitreihe und der Fondsname zur Verfügung stehen.\n",
    "\n",
    "### Vorgehen\n",
    "\n",
    "Der Workflow gliedert sich in folgende Schritte:\n",
    "1. Laden und Filtern der Daten: Fokus auf Peergroups mit ausreichend Datenbasis (mind. 50 Fonds).\n",
    "2. Erstellung eines Feature-Sets aus verschiedenen Kennzahlen und Ähnlichkeitswerten.\n",
    "3. Training von zwei Modelltypen (Random Forest und MLPClassifier) mit mehreren Feature-Kombinationen.\n",
    "4. K-Means Clustering zur Gruppierung nach quantitativen Merkmalen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importieren der nötigen Packete und Kennzahlen aus Kennzahlberechnung.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pfade zu den berechneten Kennzahlen\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten laden und filtern (Vorbereitung für Machine Learning)\n",
    "\n",
    "In diesem Abschnitt werden die berechneten Kennzahlen aus den benötigten Daten aus pickle-Dateien geladen und Fondsdaten aus der `Returns.xlsx`. Die Kennzahlen werden für die Features der ML-Modelle benötigt und die Fondsdaten, um die Fonds zu Filtern die für das Training der Modelle genutzt werden.\n",
    "\n",
    "Da einige Peergroups zu wenige Fonds enthalten, um aussagekräftige Trainingsdaten zu liefern, werden nur Peergroups mit mehr als 50 Fonds berücksichtigt. Um die Fonds die verwendet werden sollen zu Filtern, wird `valid_ISIN` mit den Fonds definiert, die in einer Peergroup mit mehr als 50 Fonds sind.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./Ergebnisse\"\n",
    "\n",
    "# Fondsdaten laden für Mapping der ISIN und Peergroup für die spätere Label-Zuordnung\n",
    "returns_df = pd.read_excel('./Daten/Returns.xlsx')\n",
    "returns_df.drop(index=[0, 1, 2, 3, 4], inplace=True)\n",
    "returns_df.drop(['Ranking'], axis=1, inplace=True)\n",
    "fonds_zu_peergroup = dict(zip(returns_df['ISIN'], returns_df['Peergroup']))\n",
    "\n",
    "# Laden der berechneten Kennzahlen\n",
    "with open('./Ergebnisse/Rendite.pkl', 'rb') as f:\n",
    "    rendite_data = pickle.load(f)\n",
    "with open('./Ergebnisse/Vola.pkl', 'rb') as f:\n",
    "    vola_data = pickle.load(f)\n",
    "with open('./Ergebnisse/Sharpe.pkl', 'rb') as f:\n",
    "    sharpe_data = pickle.load(f)\n",
    "with open('./Ergebnisse/Omega.pkl', 'rb') as f:\n",
    "    omega_data = pickle.load(f)\n",
    "with open('./Ergebnisse/Korrelationen.pkl', 'rb') as f:\n",
    "    korrelationen_data = pickle.load(f)\n",
    "with open('./Ergebnisse/WorstMonth.pkl', 'rb') as f:\n",
    "    worstmonth_data = pickle.load(f)\n",
    "with open('./Ergebnisse/MaxDD.pkl', 'rb') as f:\n",
    "    maxdd_data = pickle.load(f)\n",
    "\n",
    "# Filtern der Peergroups mit mehr als 50 Fonds, da nur diese für die Modelle genutzt werden\n",
    "peergroup_counts = returns_df.groupby('Peergroup')['ISIN'].nunique()\n",
    "peergroups_to_keep = peergroup_counts[peergroup_counts > 50].index\n",
    "\n",
    "# Filtern der Fonds, die in den Peergroups sind, die für die Modelle genutzt werden\n",
    "Renditen_filtered = returns_df[returns_df['Peergroup'].isin(peergroups_to_keep)].copy()\n",
    "isin_zu_peergroup = dict(zip(Renditen_filtered['ISIN'], Renditen_filtered['Peergroup']))\n",
    "valid_ISIN = set(Renditen_filtered['ISIN'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature-Erstellung für das Modelltraining\n",
    "\n",
    "In diesem Abschnitt werden die Features für die Machine-Learning-Modelle erstellt.\n",
    "\n",
    "Zunächst werden die rollierenden Basiskennzahlen für die Zeitfenster 12, 24, 36 und 60 Monate extrahiert. Für jedes Zeitfenster wird dabei der jeweils letzte verfügbare Wert verwendet. Hierbei werden die kennzahlen die mit den Peergroup_Benchmarks nicht berücksichtigt, da diese durch die zurodnung zur Peergroup_Benchmarks eine Verbindung zur Peergroup die vorhergesagt werden soll haben. Die Basiskennzahlen sollen dem Model informationen über das Rendte-Risiko-Profil der Fonds liefern.\n",
    "\n",
    "Zusätzlich werden vier nicht überlappende 12-Monats-Zeiträume vor dem letzten Zeitpunkt erstellt. Diese sollen helfen, Entwicklungen in der Vergangenheit als separate Zeitblöcke ins Modell einzubringen.\n",
    "\n",
    "Außerdem werden die Korrelationen der Fonds zu allgemeinen Marktbenchmarks als weitere Features hinzugefügt. Diese dienen dazu informationen über das verhalten der Fonds gegenüber unterschiedlichen Anlageklassen zu liefern.\n",
    "\n",
    "Zur Ergänzung der quantitativen Features wird ein Ähnlichkeitswert zwischen dem Fondsnamen und den Namen der Peergroups berechnet. Dafür wird eine TF-IDF-Vektorisierung auf den Namen durchgeführt und anschließend die Kosinus-Ähnlichkeit bestimmt. Dieser Schritt wird durchgeführt, da der Fondsname häufig Informationen über die Anlagestrategie des Fonds enthält.\n",
    "\n",
    "Des Weiteren werden nur Fonds beibehalten, die mindestens 60 Monate Historie aufweisen, damit für jeden Fonds zu jedem Feature ein Wert vorhanden ist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeiträume für die verwendeten Kennzahlen definieren\n",
    "windows = ['12M', '24M', '36M', '60M']\n",
    "\n",
    "# feature DataFrame für die Sammlung aller Features initalisieren\n",
    "features = pd.DataFrame()\n",
    "\n",
    "for window in windows:\n",
    "    # Extrahieren der Basiskennzahlen über die Zeiträume für den jeweils aktuellsten Monat der Zeitreihe\n",
    "    features[f'Rendite_{window}'] = rendite_data[window].iloc[-1]\n",
    "    features[f'Vola_{window}'] = vola_data[window].iloc[-1]\n",
    "    features[f'Sharpe_{window}'] = sharpe_data[window].iloc[-1]\n",
    "    features[f'Omega_{window}'] = omega_data[window].iloc[-1]\n",
    "    features[f'WorstMonth_{window}'] = worstmonth_data[window].iloc[-1]\n",
    "    features[f'MaximumDrawdown_{window}'] = maxdd_data[window].iloc[-1]\n",
    "    # Extrahieren der Korrelationen mit den allgemeinen Benchmarks\n",
    "    for index in korrelationen_data[\"Korr_12M\"].index:\n",
    "        features[f'Korr_{index}_{window}'] = korrelationen_data[f'Korr_{window}'].loc[index]\n",
    "\n",
    "# Extrahieren der vier nicht überlappenden 12 Monats zeiträume vor dem aktuellen Zeitraum\n",
    "for i in range(4):\n",
    "    suffix = f\"12M_Block{i+1}\"\n",
    "    features[f'Rendite_{suffix}'] = rendite_data['12M'].iloc[-(12 * (i + 1))]\n",
    "    features[f'Sharpe_{suffix}'] = sharpe_data['12M'].iloc[-(12 * (i + 1))]\n",
    "    features[f'Vola_{suffix}'] = vola_data['12M'].iloc[-(12 * (i + 1))]\n",
    "\n",
    "# Mapping der FondsID zur ISIN zum Fondsnamen\n",
    "fondsid_zu_isin = returns_df[['FondsID', 'ISIN']].drop_duplicates().set_index('FondsID')['ISIN'].to_dict()\n",
    "isin_zu_name = returns_df[['ISIN', 'Fondsname']].drop_duplicates().set_index('ISIN')['Fondsname']\n",
    "fonds_namen = features.index.to_series().map(fondsid_zu_isin).map(isin_zu_name).fillna('').astype(str)\n",
    "peergroup_texts = list(peergroups_to_keep)\n",
    "\n",
    "# TF-IDF Vektorisierung\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_fonds = vectorizer.fit_transform(fonds_namen.values)\n",
    "tfidf_peergroups = vectorizer.transform(peergroup_texts)\n",
    "\n",
    "# Berechnung der Kosinus-Ähnlichkeit\n",
    "similarities = cosine_similarity(tfidf_fonds, tfidf_peergroups)\n",
    "similarity_df = pd.DataFrame(similarities, index=fonds_namen.index, columns=[f'name_sim_{pg}' for pg in peergroup_texts])\n",
    "\n",
    "# Mit Features zusammenführen\n",
    "features = features.join(similarity_df)\n",
    "\n",
    "# Mapping der FondsID zur ISIN\n",
    "fondsid_zu_isin = returns_df.reset_index().set_index('FondsID')['ISIN'].to_dict()\n",
    "features.index = features.index.map(fondsid_zu_isin)\n",
    "\n",
    "# droppen von Fonds, die weniger als 60 Monate Historie aufweisen, damit alle Fonds Werte für für alle Features aufweisen\n",
    "features.dropna(subset=[\"Rendite_60M\"], inplace=True)\n",
    "features = features.loc[features.index.isin(valid_ISIN)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelltraining: Peergroup-Klassifikation mit Random Forest & MLP\n",
    "\n",
    "In diesem Abschnitt werden Machine-Learning-Modelle trainiert, um die Fonds in Peergroups einzuordnen. Dabei handelt es sich um eine Multi-Label-Klassifikationsaufgabe, da ein Fonds mehreren Peergroups zugeordnet sein kann.\n",
    "\n",
    "Die Zielvariable (`y_multi`) wird mithilfe von One-Hot-Encoding auf Basis der ISIN-Peergroup-Zuordnung erstellt.\n",
    "\n",
    "Zur Untersuchung der Modellleistung werden verschiedene Feature-Kombinationen getestet:\n",
    "- Basis: Nur die aktuellen Kennzahlen über verschiedene Zeiträume\n",
    "- Basis+Rolling12M: Zusätzlich vier nicht überlappende 12M-Zeitblöcke\n",
    "- Basis+NameSim: Zusätzlich die Ähnlichkeitswerte basierend auf dem Fondsnamen\n",
    "- Basis+Rolling12M+NameSim: Kombination aller verfügbaren Features\n",
    "\n",
    "Zwei Modelltypen werden eingesetzt, um verschiedene Ansätze zu vergleichen:\n",
    "- Ein Random Forest Classifier (performant, robust)\n",
    "- Ein MLPClassifier (neuronales Netz), um auch komplexere Muster erkennen zu können\n",
    "\n",
    "\n",
    "Für beide Modelle werden mit `RandomizedSearchCV` passende Hyperparameter-Kombinationen getestet. Anschließend werden Accuracy und F1-Scores (macro & samples) für die Modelle auf dem Testdatensatz ausgegeben.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Testing Feature-Set: Basis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johntitz/Desktop/Datenanalyse/venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ RF: Acc: 0.5582 | F1_macro: 0.5951 | F1_samples: 0.5586\n",
      "→ MLP: Acc: 0.4965 | F1_macro: 0.4712 | F1_samples: 0.5156\n",
      "\n",
      " Testing Feature-Set: Basis+Rolling12M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johntitz/Desktop/Datenanalyse/venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/johntitz/Desktop/Datenanalyse/venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ RF: Acc: 0.5582 | F1_macro: 0.5951 | F1_samples: 0.5586\n",
      "→ MLP: Acc: 0.4965 | F1_macro: 0.4712 | F1_samples: 0.5156\n",
      "\n",
      " Testing Feature-Set: Basis+NameSim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johntitz/Desktop/Datenanalyse/venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/johntitz/Desktop/Datenanalyse/venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ RF: Acc: 0.5644 | F1_macro: 0.6010 | F1_samples: 0.5650\n",
      "→ MLP: Acc: 0.5035 | F1_macro: 0.4631 | F1_samples: 0.5241\n",
      "\n",
      " Testing Feature-Set: Basis+Rolling12M+NameSim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johntitz/Desktop/Datenanalyse/venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/johntitz/Desktop/Datenanalyse/venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ RF: Acc: 0.5869 | F1_macro: 0.6222 | F1_samples: 0.5872\n",
      "→ MLP: Acc: 0.5574 | F1_macro: 0.5455 | F1_samples: 0.5829\n",
      "\n",
      " Vergleich Random Forest:\n",
      "                          Accuracy  F1_macro  F1_samples\n",
      "Basis+Rolling12M+NameSim  0.586865  0.622154    0.587239\n",
      "Basis+NameSim             0.564412  0.601017    0.564973\n",
      "Basis                     0.558237  0.595127    0.558612\n",
      "Basis+Rolling12M          0.558237  0.595127    0.558612\n",
      "\n",
      " Vergleich MLPClassifier:\n",
      "                          Accuracy  F1_macro  F1_samples\n",
      "Basis+Rolling12M+NameSim  0.557395  0.545534    0.582889\n",
      "Basis+NameSim             0.503508  0.463092    0.524090\n",
      "Basis                     0.496492  0.471216    0.515577\n",
      "Basis+Rolling12M          0.496492  0.471216    0.515577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johntitz/Desktop/Datenanalyse/venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# erstellen der Peergroup-Labels (Zielvariablen) im Multi-Label Format mit One-Hot-Encoding\n",
    "peergroup_series = pd.Series(fonds_zu_peergroup).loc[features.index]\n",
    "y_multi = pd.get_dummies(peergroup_series).astype(int).sort_index()\n",
    "\n",
    "# Initialisierung des Scalers zur Standardisierung der Features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Definitieren der verschiedenen Feature-Kombinationen\n",
    "feature_sets = {\n",
    "    'Basis': features.filter(regex='^(Rendite|Vola|Sharpe|Omega|WorstMonth|MaximumDrawdown)_'),\n",
    "    'Basis+Rolling12M': features.filter(regex='^(Rendite|Vola|Sharpe|Omega|WorstMonth|MaximumDrawdown|12M_Block)_'),\n",
    "    'Basis+NameSim': features.filter(regex='^(Rendite|Vola|Sharpe|Omega|WorstMonth|MaximumDrawdown|name_sim_)'),\n",
    "    'Basis+Rolling12M+NameSim': features\n",
    "}\n",
    "# Hyperparameter für Random Forest\n",
    "rf_params = {\n",
    "    'estimator__n_estimators': [100, 200],\n",
    "    'estimator__max_depth': [30, 50],\n",
    "    'estimator__min_samples_split': [2, 5],\n",
    "}\n",
    "\n",
    "# Hyperparameter für MLP (Neural Network)\n",
    "mlp_params = {\n",
    "    'estimator__hidden_layer_sizes': [(512, 256),(256, 128), (128, 64)],\n",
    "    'estimator__activation': ['relu', 'tanh'],\n",
    "    'estimator__alpha': [0.0001, 0.001],\n",
    "    'estimator__learning_rate_init': [0.001, 0.0001],\n",
    "}\n",
    "\n",
    "# Multi-Output-Wrapper für die Modelle (mehrere Peergroup-Labels gleichzeitig)\n",
    "multi_rf = MultiOutputClassifier(RandomForestClassifier(n_jobs=-1, random_state=42))\n",
    "multi_mlp = MultiOutputClassifier(MLPClassifier(max_iter=1000, early_stopping=True, random_state=42))\n",
    "\n",
    "# Dictionaries zur Speicherung der Ergebnisse initialisieren\n",
    "results_rf = {}\n",
    "results_mlp = {}\n",
    "\n",
    "# Trainings-Loop über alle definierten Feature-Sets\n",
    "for name, X_features in feature_sets.items():\n",
    "    print(f\"\\n Testing Feature-Set: {name}\")\n",
    "\n",
    "    # Features standardisieren\n",
    "    X_scaled = pd.DataFrame(scaler.fit_transform(X_features), index=X_features.index, columns=X_features.columns)\n",
    "    \n",
    "    # Aufteilung in Trainings- und Testdaten\n",
    "    train_ids, test_ids = train_test_split(X_scaled.index, test_size=0.2, random_state=42)\n",
    "    X_train, X_test = X_scaled.loc[train_ids], X_scaled.loc[test_ids]\n",
    "    y_train_split, y_test_split = y_multi.loc[train_ids], y_multi.loc[test_ids]\n",
    "\n",
    "    # Trainieren des Random Forest Modell mit RandomizedSearchCV\n",
    "    rf_model = RandomizedSearchCV(multi_rf, rf_params, cv=3, n_jobs=-1, n_iter=6, random_state=42)\n",
    "    rf_model.fit(X_train, y_train_split)\n",
    "    preds_rf = rf_model.predict(X_test)\n",
    "    \n",
    "    # Evaluation des RF-Modells\n",
    "    acc_rf = accuracy_score(y_test_split, preds_rf)\n",
    "    f1_macro_rf = f1_score(y_test_split, preds_rf, average='macro')\n",
    "    f1_samples_rf = f1_score(y_test_split, preds_rf, average='samples')\n",
    "    results_rf[name] = {'Accuracy': acc_rf, 'F1_macro': f1_macro_rf, 'F1_samples': f1_samples_rf}\n",
    "\n",
    "    # Trainieren des MLP-Modell (Neural Network) mit RandomizedSearchCV\n",
    "    mlp_model = RandomizedSearchCV(multi_mlp, mlp_params, cv=3, n_jobs=-1, n_iter=6, random_state=42)\n",
    "    mlp_model.fit(X_train, y_train_split)\n",
    "    preds_mlp = mlp_model.predict(X_test)\n",
    "    \n",
    "    # Evaluation des MLP-Modells\n",
    "    acc_mlp = accuracy_score(y_test_split, preds_mlp)\n",
    "    f1_macro_mlp = f1_score(y_test_split, preds_mlp, average='macro')\n",
    "    f1_samples_mlp = f1_score(y_test_split, preds_mlp, average='samples')\n",
    "    results_mlp[name] = {'Accuracy': acc_mlp, 'F1_macro': f1_macro_mlp, 'F1_samples': f1_samples_mlp}\n",
    "\n",
    "    print(f\"→ RF: Acc: {acc_rf:.4f} | F1_macro: {f1_macro_rf:.4f} | F1_samples: {f1_samples_rf:.4f}\")\n",
    "    print(f\"→ MLP: Acc: {acc_mlp:.4f} | F1_macro: {f1_macro_mlp:.4f} | F1_samples: {f1_samples_mlp:.4f}\")\n",
    "\n",
    "print(\"\\n Vergleich Random Forest:\")\n",
    "print(pd.DataFrame(results_rf).T.sort_values(\"F1_samples\", ascending=False))\n",
    "\n",
    "print(\"\\n Vergleich MLPClassifier:\")\n",
    "print(pd.DataFrame(results_mlp).T.sort_values(\"F1_samples\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering zur Analyse von Fondsgruppen\n",
    "\n",
    "In diesem Abschnitt wird ein K-Means-Clustering durchgeführt, um zu prüfen, welche Fonds ein ähnliches Rendite-Risiko-Profil aufweisen. Dafür werden die aktuellsten Werte der Kennzahlen Rendite, Volatilität und Sharpe-Ratio verwendet. Die Cluster können genutzt werden um die Zusammensetzung der Benchmarks zu prüfen.\n",
    "\n",
    "Nach dem Clustering wird für jedes Cluster analysiert:\n",
    "- Wie viele Fonds diesem Cluster zugeordnet wurden\n",
    "- Welche Peergroups innerhalb des Clusters am häufigsten vorkommen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0 Analysis:\n",
      "Number of funds: 869\n",
      "\n",
      "Top Peergroups:\n",
      "Peergroup\n",
      "Equity USA                 223\n",
      "Sustainability Global      146\n",
      "Equity Global Developed    103\n",
      "Sustainability USA          95\n",
      "Equity Global               68\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cluster 1 Analysis:\n",
      "Number of funds: 1331\n",
      "\n",
      "Top Peergroups:\n",
      "Peergroup\n",
      "Sustainability Bonds Europe Corporate          128\n",
      "Corporate Bonds Europe                         119\n",
      "Diversified Bonds Global Hedged                 96\n",
      "Multi-Asset Global Bond Bias                    86\n",
      "Sustainability Multi-Asset Global Bond Bias     70\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cluster 2 Analysis:\n",
      "Number of funds: 923\n",
      "\n",
      "Top Peergroups:\n",
      "Peergroup\n",
      "Sustainability Europe    171\n",
      "Equity Europe            157\n",
      "Equity Switzerland       106\n",
      "Equity Eurozone           53\n",
      "Commodity Diversified     36\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cluster 3 Analysis:\n",
      "Number of funds: 1142\n",
      "\n",
      "Top Peergroups:\n",
      "Peergroup\n",
      "Multi-Asset Global Moderate Equity Bias                   167\n",
      "Multi-Asset Global Bond Bias                              152\n",
      "Multi-Asset Global Flexible                               129\n",
      "Sustainability Multi-Asset Global Bond Bias                79\n",
      "Sustainability Multi-Asset Global Moderate Equity Bias     73\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cluster 4 Analysis:\n",
      "Number of funds: 569\n",
      "\n",
      "Top Peergroups:\n",
      "Peergroup\n",
      "Sustainability Europe                  122\n",
      "Equity Emerging Markets Diversified     44\n",
      "Equity Europe                           41\n",
      "Equity Europe Small Cap                 35\n",
      "Equity Asia Pacific ex Japan            27\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cluster 5 Analysis:\n",
      "Number of funds: 2\n",
      "\n",
      "Top Peergroups:\n",
      "Peergroup\n",
      "Digital Assets    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cluster 6 Analysis:\n",
      "Number of funds: 1047\n",
      "\n",
      "Top Peergroups:\n",
      "Peergroup\n",
      "Sustainability Global                  264\n",
      "Equity Global                          199\n",
      "Equity Global Developed                134\n",
      "Multi-Asset Global High Equity Bias     87\n",
      "Multi-Asset Global Flexible             61\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cluster 7 Analysis:\n",
      "Number of funds: 13\n",
      "\n",
      "Top Peergroups:\n",
      "Peergroup\n",
      "Digital Assets               11\n",
      "Commodity Single              1\n",
      "Technological Innovations     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cluster 8 Analysis:\n",
      "Number of funds: 222\n",
      "\n",
      "Top Peergroups:\n",
      "Peergroup\n",
      "Equity USA Multi Factor                    51\n",
      "Listed Commodity Gold & Precious Metals    45\n",
      "Commodity Single                           25\n",
      "Commodity Sector & Single Factors          18\n",
      "Listed Commodity Diversified               17\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cluster 9 Analysis:\n",
      "Number of funds: 1618\n",
      "\n",
      "Top Peergroups:\n",
      "Peergroup\n",
      "Sustainability Europe    273\n",
      "Equity Europe            272\n",
      "Equity UK                179\n",
      "Equity Japan             108\n",
      "Equity Eurozone           92\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cluster 10 Analysis:\n",
      "Number of funds: 961\n",
      "\n",
      "Top Peergroups:\n",
      "Peergroup\n",
      "Equity Emerging Markets Diversified    171\n",
      "Equity Asia Pacific ex Japan            83\n",
      "Sustainability Europe                   65\n",
      "Listed Real Estate Global               64\n",
      "Sustainability Emerging Markets         64\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cluster 11 Analysis:\n",
      "Number of funds: 43\n",
      "\n",
      "Top Peergroups:\n",
      "Peergroup\n",
      "Commodity Single                     14\n",
      "Cleantech & Green Energy             13\n",
      "Commodity Sector & Single Factors     8\n",
      "Equity Emerging Markets China         1\n",
      "Equity Europe Small Cap               1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cluster 12 Analysis:\n",
      "Number of funds: 501\n",
      "\n",
      "Top Peergroups:\n",
      "Peergroup\n",
      "High Yield Bonds Europe            66\n",
      "Sustainability Bonds High Yield    54\n",
      "Multi-Asset Global Bond Bias       40\n",
      "Multi-Asset Global Flexible        37\n",
      "Corporate Bonds Subordinated       30\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cluster 13 Analysis:\n",
      "Number of funds: 784\n",
      "\n",
      "Top Peergroups:\n",
      "Peergroup\n",
      "Government Bonds Eurozone             117\n",
      "Sustainability Bonds Europe           108\n",
      "Diversified Bonds Europe               99\n",
      "Sustainability Bonds Global Hedged     70\n",
      "Diversified Bonds Global Hedged        67\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cluster 14 Analysis:\n",
      "Number of funds: 181\n",
      "\n",
      "Top Peergroups:\n",
      "Peergroup\n",
      "Equity Emerging Markets China      84\n",
      "Listed Real Estate Europe          42\n",
      "Sustainability Emerging Markets    14\n",
      "Cleantech & Green Energy            5\n",
      "Biotechnology & Healthcare          5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cluster 15 Analysis:\n",
      "Number of funds: 649\n",
      "\n",
      "Top Peergroups:\n",
      "Peergroup\n",
      "Sustainability Global      140\n",
      "Equity Global               68\n",
      "Equity USA                  56\n",
      "Megatrends                  40\n",
      "Equity Global Developed     34\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cluster 16 Analysis:\n",
      "Number of funds: 152\n",
      "\n",
      "Top Peergroups:\n",
      "Peergroup\n",
      "Technological Innovations          45\n",
      "Equity USA                         43\n",
      "Equity Global                      12\n",
      "Digitalisation & Cyber Security    12\n",
      "Equity USA Multi Factor             9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cluster 17 Analysis:\n",
      "Number of funds: 94\n",
      "\n",
      "Top Peergroups:\n",
      "Peergroup\n",
      "Fixed Income Global                    19\n",
      "Multi-Asset Global Bond Bias           12\n",
      "Sustainability Bonds Short Duration     8\n",
      "Multi-Asset Global Flexible             6\n",
      "Corporate Bonds Short Duration Euro     6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cluster 18 Analysis:\n",
      "Number of funds: 587\n",
      "\n",
      "Top Peergroups:\n",
      "Peergroup\n",
      "Multi-Asset Global Flexible                    70\n",
      "Sustainability Multi-Asset Global Bond Bias    61\n",
      "Multi-Asset Global Bond Bias                   60\n",
      "Emerging Market Bonds Global Local Currency    49\n",
      "Multi-Asset Risk Premia                        26\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cluster 19 Analysis:\n",
      "Number of funds: 1245\n",
      "\n",
      "Top Peergroups:\n",
      "Peergroup\n",
      "Multi-Asset Global Flexible                               303\n",
      "Multi-Asset Global Moderate Equity Bias                   263\n",
      "Multi-Asset Global High Equity Bias                       123\n",
      "Sustainability Multi-Asset Global Moderate Equity Bias     95\n",
      "Sustainability Global                                      47\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Auswahl der Features für das Clustering\n",
    "clustering_features = [\n",
    "    col for col in features.columns\n",
    "    if any(key in col for key in ['Rendite', 'Vola', 'Sharpe']) and 'Block' not in col\n",
    "]\n",
    "\n",
    "# Standardisierung der Clustering-Daten\n",
    "X_cluster = StandardScaler().fit_transform(features[clustering_features])\n",
    "\n",
    "# Clustering mit K-Means\n",
    "n_clusters = 20\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "features['Cluster'] = kmeans.fit_predict(X_cluster)\n",
    "\n",
    "# Cluster-Analyse: Zuordnung von Fonds zu Cluster & Peergroup\n",
    "labels = pd.Series(fonds_zu_peergroup).loc[features.index]\n",
    "cluster_analysis = pd.DataFrame({\n",
    "    'FondsID': features.index,\n",
    "    'Cluster': features['Cluster'],\n",
    "    'Peergroup': labels.values\n",
    "})\n",
    "\n",
    "# Ausgabe: Häufigkeit pro Cluster & Peergroup-Verteilung\n",
    "for i in range(n_clusters):\n",
    "    cluster_data = cluster_analysis[cluster_analysis['Cluster'] == i]\n",
    "    print(f\"\\nCluster {i} Analysis:\")\n",
    "    print(f\"Number of funds: {len(cluster_data)}\")\n",
    "    print(\"\\nTop Peergroups:\")\n",
    "    print(cluster_data['Peergroup'].value_counts().head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazit: Klassifikation von Fonds in Peergroups mit Machine Learning\n",
    "\n",
    "Ziel dieses Projektteils war es, ein Modell zu entwickeln, das neue Fonds automatisch einer oder mehreren passenden Peergroups zuordnet. Hintergrund dafür war, den manuellen Aufwand bei der Klassifikation zu reduzieren. Dafür wurden nur Features verwendet, die für alle Fonds breit verfügbar sind.\n",
    "\n",
    "Die Ergebnisse der getesteten Modelle (Random Forest und MLPClassifier) zeigten jedoch, dass diese insgesamt keine ausreichende Trennschärfe aufweisen, um in der Praxis eingesetzt werden zu können. Insbesondere der F1-Score, der bei keiner Variante über 0,63 lag, zeigt, dass die Modelle Schwierigkeiten haben, verlässlich zu klassifizieren. Die Unterschiede zwischen den Peergroups scheinen auf Basis der Rendite-Risiko-Kennzahlen allein nicht ausreichend stark zu sein, um sie zuverlässig zu trennen. Auch der Einsatz des Fondsnamens als textbasiertes Zusatzfeature konnte das Modell nur bedingt verbessern.\n",
    "\n",
    "**Random Forest:**  \n",
    "zeigte insgesamt bessere Ergebnisse als das neuronale Netz. Die besten Resultate wurden mit der Kombination aus Basiskennzahlen, Rolling-Blöcken und Namensähnlichkeit erzielt:\n",
    "\n",
    "| Feature-Set                  | Accuracy | F1_macro | F1_samples |\n",
    "|-----------------------------|----------|----------|------------|\n",
    "| Basis+Rolling12M+NameSim    | 0.587    | 0.622    | 0.587      |\n",
    "| Basis+NameSim               | 0.564    | 0.601    | 0.565      |\n",
    "| Basis                       | 0.558    | 0.595    | 0.559      |\n",
    "| Basis+Rolling12M            | 0.558    | 0.595    | 0.559      |\n",
    "\n",
    "**MLPClassifier:**  \n",
    "schnitt insgesamt schlechter ab:\n",
    "\n",
    "| Feature-Set                  | Accuracy | F1_macro | F1_samples |\n",
    "|-----------------------------|----------|----------|------------|\n",
    "| Basis+Rolling12M+NameSim    | 0.557    | 0.546    | 0.583      |\n",
    "| Basis+NameSim               | 0.504    | 0.463    | 0.524      |\n",
    "| Basis                       | 0.496    | 0.471    | 0.516      |\n",
    "| Basis+Rolling12M            | 0.496    | 0.471    | 0.516      |\n",
    "\n",
    "Ein möglicher Grund für die Ergebnisse ist, dass die betrachteten Märkte zu stark korreliert sind, um die Fonds allein über die Kennzahlen aus den Renditezeitreihen unterscheiden zu können. Auch die Fondsnamen scheinen nicht ausreichend Informationen über die Anlagestrategie zu liefern. Zusätzlich könnten die Peergroups auch zu kleinteilig definiert sein, wodurch deutlich mehr Informationen nötig wären, um die Unterschiede zwischen ihnen sauber zu erfassen. Vor diesem Hintergrund können die Modelle nicht genutzt werden, um die manuelle Klassifikation zu ersetzen.\n",
    "\n",
    "### Clustering zur Analyse von Peergroups\n",
    "\n",
    "Das zusätzlich durchgeführte K-Means-Clustering zeigte, dass Fonds einer Peergroup häufig in unterschiedlichen Clustern landen. Gleichzeitig fanden sich Fonds aus verschiedenen Peergroups, aber mit ähnlicher Ausrichtung (z. B. gleiche Region oder Anlageklasse), im selben Cluster wieder. Auch das spricht dafür, dass sich Peergroups mit den hier genutzten quantitativen Informationen nicht klar abgrenzen lassen.\n",
    "\n",
    "Die Ergebnisse bestätigen die Annahme, dass zusätzliche qualitative Informationen notwendig wären, um eine verlässliche Peergroup-Klassifikation per Machine Learning zu ermöglichen.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
